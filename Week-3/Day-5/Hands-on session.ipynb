{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637afc87",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM) Classification\n",
    "\n",
    "In this exercise, you will work with a synthetic dataset and implement a Support Vector Machines (SVM) classifier using scikit-learn. SVM is a powerful algorithm for binary classification tasks and is widely used in various applications. Your task is to train the SVM model on the given dataset and evaluate its performance using accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2D grid of points\n",
    "n = 60\n",
    "\n",
    "x = np.linspace(-2*np.pi, 3*np.pi, n)\n",
    "y = np.linspace(-2*np.pi, 3*np.pi, n)\n",
    "\n",
    "# TODO: Create a meshgrid of x and y\n",
    "X, Y = # TODO\n",
    "# What does meshgrid do?\n",
    "\n",
    "# TODO: Calculate the z values as the cos(x) + cos(y) + noise with std=1/5\n",
    "Z = # TODO\n",
    "\n",
    "# What does this do?\n",
    "X = np.hstack((X.reshape((n**2, 1)), Y.reshape((n**2, 1))))\n",
    "y = (Z > 0).reshape(n**2, 1)\n",
    "\n",
    "# TODO: Split the data into training and testing sets\n",
    "test_size = # TODO\n",
    "X_train, X_test, y_train, y_test = # TODO\n",
    "\n",
    "# Why do we need to split our data?\n",
    "\n",
    "# Reshape the target variables\n",
    "n_samples = n ** 2\n",
    "y_train = y_train.reshape((int(n_samples * (1 - test_size)), 1))\n",
    "y_test = y_test.reshape((int(n_samples * test_size), 1))\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print()\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef297fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the data\n",
    "# Create a 1x2 grid for subplots\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# TODO: Display the heatmap for Z using the 'hot' colormap\n",
    "plt.imshow(# TODO, cmap=# TODO)\n",
    "# Add a colorbar to the first subplot with shrink factor 0.49 to adjust its size\n",
    "plt.colorbar(shrink=0.49)\n",
    "\n",
    "# Set the title for the first subplot\n",
    "plt.title(\"Heatmap of Z\")\n",
    "# Set the axis title for the first subplot\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "# Set the second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# TODO: Display the heatmap for Y (reshaped to an n x n matrix) without specifying the colormap (uses default)\n",
    "plt.imshow(# TODO)\n",
    "# Add a colorbar to the second subplot with shrink factor 0.49 to adjust its size\n",
    "plt.colorbar(shrink=0.49)\n",
    "\n",
    "# Set the title for the second subplot\n",
    "plt.title(\"Heatmap of Y\")\n",
    "# Set the axis title for the second subplot\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c450ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the SVM model first with a linear kernel\n",
    "svm_classifier = # TODO\n",
    "svm_classifier.fit(# TODO)\n",
    "\n",
    "# TODO: Predict the train and test datasets\n",
    "y_train_pred = # TODO\n",
    "y_test_pred = # TODO\n",
    "\n",
    "# TODO: Assess the accuracy of the model\n",
    "train_accuracy = # TODO\n",
    "test_accuracy = # TODO\n",
    "\n",
    "# Comment the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce47a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary and data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the decision boundary\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# TODO: Plot the test data points\n",
    "plt.scatter(# TODO, # TODO, c=y_test, cmap='viridis', edgecolor='black', linewidth=1, marker='o', label='Test Data')\n",
    "\n",
    "plt.title('SVM Classifier Decision Boundary')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(ticks=[0, 1], label='Class')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90429887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the SVM model first with a rbf kernel\n",
    "svm_classifier = # TODO\n",
    "svm_classifier.fit(# TODO)\n",
    "\n",
    "# TODO: Predict the train and test datasets\n",
    "y_train_pred = # TODO\n",
    "y_test_pred = # TODO\n",
    "\n",
    "# TODO: Assess the accuracy of the model\n",
    "train_accuracy = # TODO\n",
    "test_accuracy = # TODO\n",
    "\n",
    "# Comment the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f82d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary and data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the decision boundary\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# TODO: Plot the test data points\n",
    "plt.scatter(# TODO, # TODO, c=y_test, cmap='viridis', edgecolor='black', linewidth=1, marker='o', label='Test Data')\n",
    "\n",
    "plt.title('SVM Classifier Decision Boundary')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(ticks=[0, 1], label='Class')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32097636",
   "metadata": {},
   "source": [
    "# Random Forest (RF) Classification\n",
    "\n",
    "In this exercise, you will work with a synthetic dataset and implement a Random Forest (RF) classifier using scikit-learn. Random Forest is a powerful algorithm for binary classification tasks and is widely used in various applications. Your task is to train the RF model on the given dataset and evaluate its performance using accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2D grid of points\n",
    "n = 60\n",
    "\n",
    "x = np.linspace(-2*np.pi, 3*np.pi, n)\n",
    "y = np.linspace(-2*np.pi, 3*np.pi, n)\n",
    "\n",
    "# TODO: Create a meshgrid of x and y\n",
    "X, Y = # TODO\n",
    "# What does meshgrid do?\n",
    "\n",
    "# TODO: Calculate the z values as the cos(x) + cos(y) + noise with std=1/5\n",
    "Z = # TODO\n",
    "\n",
    "# What does this do?\n",
    "X = np.hstack((X.reshape((n**2, 1)), Y.reshape((n**2, 1))))\n",
    "y = (Z > 0).reshape(n**2, 1)\n",
    "\n",
    "# TODO: Split the data into training and testing sets\n",
    "test_size = # TODO\n",
    "X_train, X_test, y_train, y_test = # TODO\n",
    "\n",
    "# Why do we need to split our data?\n",
    "\n",
    "# Reshape the target variables\n",
    "n_samples = n ** 2\n",
    "y_train = y_train.reshape((int(n_samples * (1 - test_size)), 1))\n",
    "y_test = y_test.reshape((int(n_samples * test_size), 1))\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print()\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the data\n",
    "# Create a 1x2 grid for subplots\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# TODO: Display the heatmap for Z using the 'hot' colormap\n",
    "plt.imshow(# TODO, cmap=# TODO)\n",
    "# Add a colorbar to the first subplot with shrink factor 0.49 to adjust its size\n",
    "plt.colorbar(shrink=0.49)\n",
    "\n",
    "# Set the title for the first subplot\n",
    "plt.title(\"Heatmap of Z\")\n",
    "# Set the axis title for the first subplot\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "# Set the second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# TODO: Display the heatmap for Y (reshaped to an n x n matrix) without specifying the colormap (uses default)\n",
    "plt.imshow(# TODO)\n",
    "# Add a colorbar to the second subplot with shrink factor 0.49 to adjust its size\n",
    "plt.colorbar(shrink=0.49)\n",
    "\n",
    "# Set the title for the second subplot\n",
    "plt.title(\"Heatmap of Y\")\n",
    "# Set the axis title for the second subplot\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a39a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the Random Forest model on the training dataset\n",
    "rf_classifier = # TODO\n",
    "rf_classifier.fit(# TODO)\n",
    "\n",
    "# TODO: Predict the classes for both the training and testing datasets\n",
    "y_train_pred = # TODO\n",
    "y_test_pred = # TODO\n",
    "\n",
    "# TODO: Assess the accuracy of the model and comment on the results\n",
    "train_accuracy = # TODO\n",
    "test_accuracy = # TODO\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71208a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary and data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the decision boundary\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = rf_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# TODO: Plot the test data points\n",
    "plt.scatter(# TODO, # TODO, c=y_test, cmap='viridis', edgecolor='black', linewidth=1, marker='o', label='Test Data')\n",
    "\n",
    "plt.title('RF Classifier Decision Boundary')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(ticks=[0, 1], label='Class')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can you achieve better results than the previous models using logistic regression?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
