{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961e6ee0",
   "metadata": {},
   "source": [
    "# Linear Regression: Cost Function and Gradient Implementation\n",
    "\n",
    "In this coding exercise, you will be implementing the cost function and gradient function for linear regression. The cost function measures the error between the predicted values and the actual values, while the gradient function calculates the derivatives of the cost function with respect to the model parameters. You will use a synthetic dataset to test your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6402e5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's simulate some data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate feature matrix X with a linear trend\n",
    "n_samples = 1000\n",
    "x_axis = np.linspace(-5, 5, n_samples).reshape(-1, 1)\n",
    "\n",
    "# Generate feature matrix X with columns [1, x_axis, cos(frequency*x_axis)]\n",
    "X = np.hstack((np.ones((n_samples, 1)), x_axis, np.cos(0.8 * x_axis)))\n",
    "\n",
    "# Generate target variable y with a linear trend plus a cosine function\n",
    "intercept = 1.5\n",
    "slope = 0.7\n",
    "amplitude = 4\n",
    "\n",
    "# True model parameters\n",
    "theta_true = np.array([intercept, slope, amplitude])\n",
    "\n",
    "# Generate noise\n",
    "noise = np.random.normal(0, 2, size=(n_samples))\n",
    "\n",
    "# Define y = intercept + slope*x + amplitude*cos(frequency*x) + noise\n",
    "y = X @ theta_true + noise\n",
    "\n",
    "# TODO: Split the data into training (80%) and testing (20%) sets\n",
    "test_size = # TODO\n",
    "X_train, X_test, y_train, y_test = # TODO\n",
    "\n",
    "# Why do we need to split our data?\n",
    "\n",
    "# Reshape the target variables\n",
    "y_train = y_train.reshape((int(n_samples * (1 - test_size)), 1))\n",
    "y_test = y_test.reshape((int(n_samples * test_size), 1))\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print()\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402a0ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO Plot the simulated data (train and test)\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.scatter(X_train[:, 1], # TODO, color='blue', label='Training Data')\n",
    "plt.scatter(X_test[:, 1], # TODO, color='red', label='Testing Data')\n",
    "\n",
    "# TODO Plot the estimated curve\n",
    "plt.plot(X[:, 1], X @ # TODO, color='green', label='True Function')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Simulated Data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the predict function for linear regression\n",
    "def predict(X, theta):\n",
    "    \"\"\"\n",
    "    Predict the target variable using the linear regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (n, p), where n is the number of samples and p is the number of features.\n",
    "    theta (numpy.ndarray): Model parameters of shape (p, 1).\n",
    "    \n",
    "    Returns:\n",
    "    y_hat (numpy.ndarray): Predicted target values of shape (p, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    y_hat = # TODO\n",
    "    \n",
    "    return y_hat\n",
    "\n",
    "\n",
    "# TODO: Implement the cost function for linear regression\n",
    "def cost_function(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost function for linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (n, p), where n is the number of samples and p is the number of features.\n",
    "    y (numpy.ndarray): Target values of shape (n, 1).\n",
    "    theta (numpy.ndarray): Model parameters of shape (p, 1).\n",
    "    \n",
    "    Returns:\n",
    "    mse (float): Cost value corresponding to the mean squared error.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of samples\n",
    "    n = len(y)\n",
    "    \n",
    "    # TODO: Predict the target variable using the linear regression model predict function\n",
    "    y_hat = # TODO\n",
    "    \n",
    "    # TODO: Compute the mean squared error between the actual and predicted values\n",
    "    mse = # TODO\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "# TODO: Implement the gradient function for linear regression\n",
    "def gradient_function(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the cost function for linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Feature matrix of shape (n, p), where n is the number of samples and p is the number of features.\n",
    "    y (numpy.ndarray): Target values of shape (n, 1).\n",
    "    theta (numpy.ndarray): Model parameters of shape (p,).\n",
    "    \n",
    "    Returns:\n",
    "    gradient (numpy.ndarray): Gradient vector of shape (p, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(y)\n",
    "    \n",
    "    # TODO: Predict the target variable using the linear regression model predict function\n",
    "    y_hat = # TODO\n",
    "    \n",
    "    # TODO: Compute the error term by subtracting the actual values from the predicted values\n",
    "    error = # TODO\n",
    "    \n",
    "    # TODO: Compute the gradient using X.transpose multuplied by the error vector\n",
    "    gradient = # TODO\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "\n",
    "# TODO: Implment the train function to learn the weights of the linear regression model using gradient descent\n",
    "def train_model_optimization(X_train, y_train, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Train the linear regression model using gradient descent optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): Feature matrix of shape (n, p) for training data.\n",
    "    y_train (numpy.ndarray): Target values of shape (n,) for training data.\n",
    "    learning_rate (float): Learning rate for gradient descent.\n",
    "    num_iterations (int): Number of iterations for training.\n",
    "    \n",
    "    Returns:\n",
    "    theta (numpy.ndarray): Model parameters of shape (p, 1).\n",
    "    costs_train (list): List of training costs at each iteration.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, p = X_train.shape\n",
    "    theta = np.zeros((p, 1))\n",
    "    costs_train = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # TODO: Compute the gradient\n",
    "        gradient = # TODO\n",
    "        \n",
    "        # TODO: Update the parameters using gradient descent\n",
    "        theta -= # TODO\n",
    "        \n",
    "        # TODO: Compute the cost for training data\n",
    "        cost_train = # TODO\n",
    "        \n",
    "        # Append the costs to the respective lists\n",
    "        costs_train.append(cost_train)\n",
    "        \n",
    "    return theta, costs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bf26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the linear regression model using optimization with different learning rates and number of iterations\n",
    "lr1 = # TODO\n",
    "num_iter1 = # TODO\n",
    "theta_hat1, train_costs1 = # TODO\n",
    "\n",
    "lr2 = # TODO\n",
    "num_iter2 = # TODO\n",
    "theta_hat2, train_costs2 = # TODO\n",
    "\n",
    "lr3 = # TODO\n",
    "num_iter3 = # TODO\n",
    "theta_hat3, train_costs3 = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e40fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cost functions for the three scenarios\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "# TOD): Plot the cost function for scenario 2\n",
    "plt.plot(# TODO, label=f'Scenario 2: lr={lr2}, num_iter={num_iter2}')\n",
    "\n",
    "# TOD): Plot the cost function for scenario 1\n",
    "plt.plot(# TODO, label=f'Scenario 1: lr={lr1}, num_iter={num_iter1}')\n",
    "\n",
    "# TOD): Plot the cost function for scenario 3\n",
    "plt.plot(# TODO, label=f'Scenario 3: lr={lr3}, num_iter={num_iter3}')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Cost Functions for Different Scenarios')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ef092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the fitted curves for the three scenarios\n",
    "plt.figure(figsize=(8, 3))  # Create a new figure with a specified size\n",
    "\n",
    "# TODO: Plot the training testing data points\n",
    "plt.scatter(X_train[:, 1], # TODO, color='blue', label='Training Data')\n",
    "plt.scatter(X_test[:, 1], # TODO, color='red', label='Testing Data')\n",
    "\n",
    "# TODO: Plot the true function line\n",
    "plt.plot(X[:, 1], X @ # TODO, color='green', label='True Function', linewidth=5)\n",
    "\n",
    "# TODO: Plot the estimation function line for scenario 1, 2 and 3\n",
    "plt.plot(X[:, 1], X @ # TODO, color='black', label='Estimation Function scenario 1', linewidth=3)\n",
    "plt.plot(X[:, 1], X @ # TODO, color='yellow', label='Estimation Function scenario 2', linewidth=3)\n",
    "plt.plot(X[:, 1], X @ # TODO, color='orange', label='Estimation Function scenario 3', linewidth=3)\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title('Simulated Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display true theta and estimated theta\n",
    "# What are your remarks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implment the train function to learn the weights of the linear regression model using gradient descent\n",
    "def train_model_closed_form_solution(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the linear regression model using closed form solution.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): Feature matrix of shape (n, p) for training data.\n",
    "    y_train (numpy.ndarray): Target values of shape (n,) for training data.\n",
    "    \n",
    "    Returns:\n",
    "    theta (numpy.ndarray): Model parameters of shape (p, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Compute theta using the estimation equation\n",
    "    theta = # TODO\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the linear regression model using closed form solution\n",
    "theta_hat_closed_form = # TODO\n",
    "\n",
    "# Evaluate the performance of the model using mean squared error\n",
    "mse_train = # TODO\n",
    "mse_test = # TODO\n",
    "\n",
    "print(\"Train Mean Squared Error:\", mse_train)\n",
    "print(\"Test  Mean Squared Error:\", mse_test)\n",
    "\n",
    "# What do you think? of this results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display true theta based on optimization and closed form solution\n",
    "# What are your remarks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd60a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the fitted curves using optimization vs closed form solution\n",
    "plt.figure(figsize=(8, 3))  # Create a new figure with a specified size\n",
    "\n",
    "# Plot the training testing data points\n",
    "plt.scatter(X_train[:, 1], # TODO, color='blue', label='Training Data')\n",
    "plt.scatter(X_test[:, 1], # TODO, color='red', label='Testing Data')\n",
    "\n",
    "# Plot the true function line\n",
    "plt.plot(X[:, 1], X @ # TODO, color='green', label='True Function', linewidth=5)\n",
    "\n",
    "# TODO: Plot the estimation function based on optimization solution\n",
    "plt.plot(X[:, 1], X @ # TODO, color='black', label='Optimization solution', linewidth=3)\n",
    "\n",
    "# TODO: Plot the estimation function based on closed form solution\n",
    "plt.plot(X[:, 1], X @ # TODO, color='yellow', label='Closed form solution', linewidth=3)\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title('Simulated Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712242a9",
   "metadata": {},
   "source": [
    "# Linear Regression:  California housing case study\n",
    "\n",
    "In this coding exercise, you will use the linear regression algorithm that you coded previously to study a real dataset. You will split it into training and testing data, normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ee4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (e.g., California housing dataset from scikit-learn)\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# TODO: Split the dataset into training and testing data (80% train, 20% test). Use the train_test_split() function\n",
    "X_train, X_test, y_train, y_test = # TODO\n",
    "\n",
    "# TODO: Normalize the dataset\n",
    "scaler = # TODO\n",
    "X_train = # TODO\n",
    "X_test = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the dataset about? print data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the linear regression model\n",
    "learning_rate = # TODO\n",
    "num_iterations = # TODO\n",
    "\n",
    "# TODO: Train the model using both optimization and closed form approaches\n",
    "theta_hat_opt, _ = # TODO\n",
    "theta_hat_cfs = # TODO\n",
    "\n",
    "# TODO: Evaluate the performance of the model using the cost function on train and test datasets\n",
    "mse_train_opt = # TODO\n",
    "mse_test_opt = # TODO\n",
    "\n",
    "# TODO: Evaluate the performance of the model using the cost function on train and test datasets\n",
    "mse_train_cfs = # TODO\n",
    "mse_test_cfs = # TODO\n",
    "\n",
    "print(\"Train Mean Squared Error (Optimization):\", mse_train_opt)\n",
    "print(\"Test  Mean Squared Error (Optimization):\", mse_test_opt)\n",
    "print()\n",
    "print(\"Train Mean Squared Error (Closed-form solution):\", mse_train_cfs)\n",
    "print(\"Test  Mean Squared Error (Closed-form solution):\", mse_test_cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the parameter estimates\n",
    "# Interpret the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c11699",
   "metadata": {},
   "source": [
    "# Linear Regression using scikit-learn\n",
    "\n",
    "In this coding exercise, you will apply linear regression to the California Housing dataset using the scikit-learn library. The dataset contains information about housing prices in various districts of California, along with several features that can be used to predict the housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfa788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# TODO: Create a linear regression model using LinearRegression\n",
    "model = # TODO\n",
    "\n",
    "# TODO: Fit the model to the training data using .fit() method\n",
    "\n",
    "# TODO: Extract the coefficients from the trained model using .coef_ attribute\n",
    "coef = # TODO\n",
    "print(\"Estimated coefficients:\", coef)\n",
    "\n",
    "# TODO: Make predictions on the test data using .predict() method\n",
    "y_train_pred = # TODO\n",
    "y_test_pred = # TODO\n",
    "\n",
    "# TODO: Calculate the mean squared error using mean_squared_error function\n",
    "mse_train = # TODO\n",
    "mse_test = # TODO\n",
    "\n",
    "# Print the mean squared error\n",
    "print()\n",
    "print(\"Mean Squared Error (train):\", mse_train)\n",
    "print(\"Mean Squared Error (test):\", mse_test)\n",
    "\n",
    "# What are your thoughts?\n",
    "# Do you see significant differences between sklearn results and your results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
