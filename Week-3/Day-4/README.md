# Day 4: Introduction to k-Nearest Neighbors (k-NN) and Decision Trees (DT)

In this session, we will explore two popular algorithms for classification: k-Nearest Neighbors (k-NN) and Decision Trees (DT). These algorithms are widely used in Machine Learning for making predictions and solving classification problems. Through hands-on exercises, you will gain practical experience in implementing and evaluating k-NN and DT models in Python.

## Schedule

### Part 1: Introduction to k-Nearest Neighbors (k-NN)
- Understanding the concept of k-NN and its working mechanism
- Exploring distance metrics for finding nearest neighbors
- Implementing k-NN in Python
- Evaluating the performance of k-NN models

### Part 2: Introduction to Decision Trees (DT)
- Understanding the basics of Decision Trees and how they create decision boundaries
- Implementing Decision Trees for classification tasks in Python
- Evaluating the performance of Decision Tree models

### Part 3: Hands-on session
- Implementing the k-NN model using sklearn 
- Implementing the decision trees model using sklearn 
- Visualizing decision boundary
- Evaluating the performance of both models

## Additional Resources
- [k-Nearest Neighbors (k-NN)](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)
- [k-NN in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
- [Decision Trees (DT)](https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96)
- [Decision Trees in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)

## Getting Help

If you have any questions or need assistance during the hands-on session, feel free to reach out to the teaching assistants.

Happy coding!
