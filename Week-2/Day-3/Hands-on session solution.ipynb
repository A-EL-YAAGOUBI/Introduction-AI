{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe06f03",
   "metadata": {},
   "source": [
    "## Handling missing data and imputation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0eaf1",
   "metadata": {},
   "source": [
    "### Exercise 1: Handling Missing Data - Dropping Rows\n",
    "\n",
    "You are working on a machine learning project where you have collected data about customers, including their age, income, and purchase behavior. However, some rows have missing values for the purchase behavior column. Your task is to handle the missing data by dropping the rows with missing purchase behavior values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2796f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Income  Purchase\n",
      "0   32   50000       1.0\n",
      "2   45   75000       0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Age': [32, 28, 45, 35],\n",
    "    'Income': [50000, 60000, 75000, 80000],\n",
    "    'Purchase': [1, None, 0, None]\n",
    "})\n",
    "\n",
    "# TODO: Drop rows with missing purchase feature values. Use the dropna() method\n",
    "df.dropna(subset=['Purchase'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "# What are the advantages and limitations of such approach?\n",
    "\n",
    "# Advantages of dropping rows with missing values:\n",
    "# # Ensures data quality and reliability.\n",
    "# # Provides a straightforward and effective solution.\n",
    "\n",
    "# Limitations of dropping rows with missing values:\n",
    "# # Results in data loss and reduced sample size.\n",
    "# # Can introduce bias if missing values are related to certain patterns or variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00fdaa",
   "metadata": {},
   "source": [
    "### Exercise 2: Handling Missing Data - Imputing with Mean Value\n",
    "\n",
    "You are analyzing a dataset of student performance in various subjects. However, some scores are missing, represented as `NaN`. Your task is to handle the missing data by imputing the missing scores with the mean score of the available scores for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e68003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject  Score\n",
      "0      Math  80.00\n",
      "1   Science  90.00\n",
      "2   English  83.75\n",
      "3      Math  70.00\n",
      "4   History  83.75\n",
      "5      Math  95.00\n",
      "6   Science  80.00\n",
      "7   English  90.00\n",
      "8      Math  83.75\n",
      "9   History  70.00\n",
      "10     Math  83.75\n",
      "11  Science  95.00\n",
      "12  English  80.00\n",
      "13     Math  90.00\n",
      "14  History  83.75\n",
      "15     Math  70.00\n",
      "16  Science  83.75\n",
      "17  English  95.00\n",
      "18     Math  80.00\n",
      "19  History  90.00\n",
      "20     Math  83.75\n",
      "21  Science  70.00\n",
      "22  English  83.75\n",
      "23     Math  95.00\n",
      "24  History  80.00\n",
      "25     Math  90.00\n",
      "26  Science  83.75\n",
      "27  English  70.00\n",
      "28     Math  83.75\n",
      "29  History  95.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Subject': ['Math', 'Science', 'English', 'Math', 'History']*6,\n",
    "    'Score': [80, 90, np.nan, 70, np.nan, 95]*5\n",
    "})\n",
    "\n",
    "# TODO: Calculate the mean score for each subject\n",
    "mean_scores = df.groupby('Subject')['Score'].mean()\n",
    "\n",
    "# TODO: Impute missing scores with the mean score for each subject. Use the transform() method and a lambda expression\n",
    "df['Score'] = df.groupby('Subject')['Score'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "# What are the advantages and limitations of such approach?\n",
    "\n",
    "# Advantages of imputing missing values with mean values:\n",
    "# # Retains data when missing values are few.\n",
    "# # Maintains distribution and statistical properties.\n",
    "# # Provides reasonable estimates in random cases.\n",
    "\n",
    "# Limitations of imputing missing values with mean values:\n",
    "# # Assumes missing values are MCAR/MAR, introducing bias.\n",
    "# # Underestimates variability by assigning the same value.\n",
    "# # Artificially inflates sample size with many missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb29d4",
   "metadata": {},
   "source": [
    "## Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c63884",
   "metadata": {},
   "source": [
    "### Exercise 3: Merging options\n",
    "\n",
    "In this exercise, you will work with two DataFrames containing information about authors and their citation counts. Your task is to merge the DataFrames based on the \"Author\" column and explore different merge types (left, right, inner, and outer) to understand the relationship between authors and their citation counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b5c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Left Merge:\n",
      "                   Paper Title         Author  Citations\n",
      "0             AI in Healthcare  Youssef Saeed       50.0\n",
      "1  Machine Learning Algorithms     Fatima Ali      100.0\n",
      "2  Natural Language Processing   Ahmed Hassan        NaN\n",
      "\n",
      "Right Merge:\n",
      "                           Paper Title         Author  Citations\n",
      "0                     AI in Healthcare  Youssef Saeed         50\n",
      "1          Machine Learning Algorithms     Fatima Ali        100\n",
      "2  Deep Learning for Image Recognition            NaN         75\n",
      "\n",
      "Inner Merge:\n",
      "                   Paper Title         Author  Citations\n",
      "0             AI in Healthcare  Youssef Saeed         50\n",
      "1  Machine Learning Algorithms     Fatima Ali        100\n",
      "\n",
      "Outer Merge:\n",
      "                           Paper Title         Author  Citations\n",
      "0                     AI in Healthcare  Youssef Saeed       50.0\n",
      "1          Machine Learning Algorithms     Fatima Ali      100.0\n",
      "2          Natural Language Processing   Ahmed Hassan        NaN\n",
      "3  Deep Learning for Image Recognition            NaN       75.0\n"
     ]
    }
   ],
   "source": [
    "# Define the first DataFrame with paper titles and authors' names\n",
    "df1 = pd.DataFrame({\n",
    "    'Paper Title': ['AI in Healthcare', 'Machine Learning Algorithms', 'Natural Language Processing'],\n",
    "    'Author': ['Youssef Saeed', 'Fatima Ali', 'Ahmed Hassan']\n",
    "})\n",
    "\n",
    "# Define the second DataFrame with paper titles and citation counts\n",
    "df2 = pd.DataFrame({\n",
    "    'Paper Title': ['AI in Healthcare', 'Machine Learning Algorithms', 'Deep Learning for Image Recognition'],\n",
    "    'Citations': [50, 100, 75]\n",
    "})\n",
    "\n",
    "# TODO: Perform left merge. Use merge() method\n",
    "left_merge = pd.merge(df1, df2, on='Paper Title', how='left')\n",
    "\n",
    "# Print result\n",
    "print(\"\\nLeft Merge:\")\n",
    "print(left_merge)\n",
    "\n",
    "# TODO: Perform right merge. Use merge() method\n",
    "right_merge = pd.merge(df1, df2, on='Paper Title', how='right')\n",
    "\n",
    "# Print result\n",
    "print(\"\\nRight Merge:\")\n",
    "print(right_merge)\n",
    "\n",
    "# TODO: Perform inner merge. Use merge() method\n",
    "inner_merge = pd.merge(df1, df2, on='Paper Title', how='inner')\n",
    "\n",
    "# Print result\n",
    "print(\"\\nInner Merge:\")\n",
    "print(inner_merge)\n",
    "\n",
    "# TODO: Perform outer merge. Use merge() method\n",
    "outer_merge = pd.merge(df1, df2, on='Paper Title', how='outer')\n",
    "\n",
    "# Print result\n",
    "print(\"\\nOuter Merge:\")\n",
    "print(outer_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528b7ba",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960e63f",
   "metadata": {},
   "source": [
    "### Exercise 4: Concatenate DataFrames horizontally and vertically\n",
    "\n",
    "You have two DataFrames containing information about authors and their publications in the field of artificial intelligence. Your task is to concatenate these DataFrames horizontally and vertically to combine the data. Display the concatenated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b2b575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontally Concatenated DataFrame:\n",
      "            Author  Publication                 Author     Publication\n",
      "0  Saud Al-Mutairi    AI Review          Nora Al-Subai       AI Trends\n",
      "1   Aisha Al-Harbi   AI Journal  Abdulaziz Al-Sulaiman        AI Today\n",
      "2  Fahad Al-Dosari  AI Insights         Hala Al-Mutlaq  AI Innovations\n",
      "\n",
      "Vertically Concatenated DataFrame:\n",
      "                  Author     Publication\n",
      "0        Saud Al-Mutairi       AI Review\n",
      "1         Aisha Al-Harbi      AI Journal\n",
      "2        Fahad Al-Dosari     AI Insights\n",
      "0          Nora Al-Subai       AI Trends\n",
      "1  Abdulaziz Al-Sulaiman        AI Today\n",
      "2         Hala Al-Mutlaq  AI Innovations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define AI-papers data\n",
    "df_papers_1 = pd.DataFrame({\n",
    "    'Author': ['Saud Al-Mutairi', 'Aisha Al-Harbi', 'Fahad Al-Dosari'],\n",
    "    'Publication': ['AI Review', 'AI Journal', 'AI Insights']\n",
    "})\n",
    "\n",
    "# Define additional AI-papers data\n",
    "df_papers_2 = pd.DataFrame({\n",
    "    'Author': ['Nora Al-Subai', 'Abdulaziz Al-Sulaiman', 'Hala Al-Mutlaq'],\n",
    "    'Publication': ['AI Trends', 'AI Today', 'AI Innovations']\n",
    "})\n",
    "\n",
    "# TODO: Concatenate horizontally. Use concat() method\n",
    "horizontal_concat = pd.concat([df_papers_1, df_papers_2], axis=1)\n",
    "\n",
    "# TODO: Concatenate vertically. Use concat() method\n",
    "vertical_concat = pd.concat([df_papers_1, df_papers_2], axis=0)\n",
    "\n",
    "# TODO: Display the concatenated DataFrames\n",
    "print(\"Horizontally Concatenated DataFrame:\")\n",
    "print(horizontal_concat)\n",
    "\n",
    "print(\"\\nVertically Concatenated DataFrame:\")\n",
    "print(vertical_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91cf6f",
   "metadata": {},
   "source": [
    "## Reshaping and Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d520bf",
   "metadata": {},
   "source": [
    "### Exercise 5: More practice with Pandas\n",
    "\n",
    "You are given a DataFrame containing sales data for an AI company. The DataFrame has the following columns: \"Month\", \"Product\", \"Region\", \"Revenue\".\n",
    "\n",
    "Your task is to perform the following operations:\n",
    "\n",
    "- Pivot the DataFrame to transform it into a wide format, where each unique product becomes a separate column, and the revenue values are filled in the corresponding cells.\n",
    "- Group the data by region and calculate the total revenue for each region.\n",
    "- Normalize the revenue values by dividing them by the maximum revenue in each region.\n",
    "- Create a new column called \"Quarter\" by extracting the quarter information from the \"Month\" column.\n",
    "- Sort the DataFrame by region in ascending order and then by quarter in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e258ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoted DataFrame:\n",
      "Month      Dec     Jan     Jun    Nov\n",
      "Region                               \n",
      "North      NaN  1000.0  1200.0  900.0\n",
      "South   1350.0  1500.0  1800.0    NaN\n",
      "\n",
      "Grouped DataFrame:\n",
      "Region\n",
      "North    3100\n",
      "South    4650\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      "Normalized DataFrame:\n",
      "  Month    Product Region   Revenue\n",
      "0   Jan  Product A  North -0.877747\n",
      "1   Jan  Product B  South  0.626962\n",
      "2   Jun  Product A  North -0.275863\n",
      "3   Jun  Product B  South  1.529788\n",
      "4   Nov  Product A  North -1.178689\n",
      "5   Dec  Product B  South  0.175549\n",
      "\n",
      "DataFrame with Quarter:\n",
      "  Month    Product Region  Revenue  Quarter\n",
      "0   Jan  Product A  North     1000        1\n",
      "1   Jan  Product B  South     1500        1\n",
      "2   Jun  Product A  North     1200        2\n",
      "3   Jun  Product B  South     1800        2\n",
      "4   Nov  Product A  North      900        4\n",
      "5   Dec  Product B  South     1350        4\n",
      "\n",
      "Sorted DataFrame:\n",
      "  Month    Product Region  Revenue  Quarter\n",
      "0   Jan  Product A  North     1000        1\n",
      "2   Jun  Product A  North     1200        2\n",
      "4   Nov  Product A  North      900        4\n",
      "1   Jan  Product B  South     1500        1\n",
      "3   Jun  Product B  South     1800        2\n",
      "5   Dec  Product B  South     1350        4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Month\": [\"Jan\", \"Jan\", \"Jun\", \"Jun\", \"Nov\", \"Dec\"],\n",
    "    \"Product\": [\"Product A\", \"Product B\", \"Product A\", \"Product B\", \"Product A\", \"Product B\"],\n",
    "    \"Region\": [\"North\", \"South\", \"North\", \"South\", \"North\", \"South\"],\n",
    "    \"Revenue\": [1000, 1500, 1200, 1800, 900, 1350]\n",
    "})\n",
    "\n",
    "# TODO: Pivot the DataFrame to transform it into a wide format. Use index=\"Region\", columns=\"Month\", and values=\"Revenue\"\n",
    "pivot_df = df.pivot(index=\"Region\", columns=\"Month\", values=\"Revenue\")\n",
    "\n",
    "# TODO: Group the data by region and calculate the total revenue\n",
    "grouped_df = df.groupby(\"Region\")[\"Revenue\"].sum()\n",
    "\n",
    "# TODO: Normalize the revenue values\n",
    "normalized_df = df.copy()\n",
    "normalized_df[\"Revenue\"] = (normalized_df[\"Revenue\"] - normalized_df[\"Revenue\"].mean()) / normalized_df[\"Revenue\"].std()\n",
    "\n",
    "# TODO: Extract the quarter information from the \"Month\" column\n",
    "df[\"Quarter\"] = pd.to_datetime(df[\"Month\"], format=\"%b\").dt.quarter\n",
    "\n",
    "# TODO: Sort the DataFrame by region and quarter\n",
    "sorted_df = df.sort_values(by=[\"Region\", \"Quarter\"])\n",
    "\n",
    "# Print the results and observe the differences\n",
    "print(\"Pivoted DataFrame:\")\n",
    "print(pivot_df)\n",
    "\n",
    "print(\"\\nGrouped DataFrame:\")\n",
    "print(grouped_df)\n",
    "\n",
    "print(\"\\nNormalized DataFrame:\")\n",
    "print(normalized_df)\n",
    "\n",
    "print(\"\\nDataFrame with Quarter:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nSorted DataFrame:\")\n",
    "print(sorted_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
